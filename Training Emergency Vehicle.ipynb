{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  v7.0-398-g5cdad892 Python-3.11.9 torch-2.6.0+cpu CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete  (12 CPUs, 15.8 GB RAM, 387.8/464.9 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import utils\n",
    "display = utils.notebook_init()  # checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --img 244 --batch 16 --epochs 90 --data Emergency.yaml --weights yolov5s.pt --cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mexport: \u001b[0mdata=C:\\Users\\gravi\\Documents\\SistemLampu\\Main\\Sistem-lampu-lalu-lintas\\yolov5\\data\\coco128.yaml, weights=['runs/train/exp24/weights/best.pt'], imgsz=[640], batch_size=1, device=cpu, half=False, inplace=False, keras=False, optimize=False, int8=False, per_tensor=False, dynamic=False, cache=, simplify=False, mlmodel=False, opset=17, verbose=False, workspace=4, nms=False, agnostic_nms=False, topk_per_class=100, topk_all=100, iou_thres=0.45, conf_thres=0.25, include=['onnx']\n",
      "YOLOv5  v7.0-398-g5cdad892 Python-3.11.9 torch-2.6.0+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from runs\\train\\exp24\\weights\\best.pt with output shape (1, 25200, 7) (13.6 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.8s, saved as runs\\train\\exp24\\weights\\best.onnx (27.2 MB)\n",
      "\n",
      "Export complete (1.2s)\n",
      "Results saved to \u001b[1mC:\\Users\\gravi\\Documents\\SistemLampu\\Main\\Sistem-lampu-lalu-lintas\\yolov5\\runs\\train\\exp24\\weights\u001b[0m\n",
      "Detect:          python detect.py --weights runs\\train\\exp24\\weights\\best.onnx \n",
      "Validate:        python val.py --weights runs\\train\\exp24\\weights\\best.onnx \n",
      "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'runs\\train\\exp24\\weights\\best.onnx')  \n",
      "Visualize:       https://netron.app\n"
     ]
    }
   ],
   "source": [
    "!python export.py --weights runs/train/exp24/weights/best.pt --img 640 --batch 1 --device cpu --include onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ONNX berhasil diuji!\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import onnxruntime\n",
    "\n",
    "# Load model ONNX\n",
    "onnx_model = onnx.load(\"C:/Users/gravi/Documents/SistemLampu/Main/Sistem-lampu-lalu-lintas/yolov5/runs/train/exp24/weights/best.onnx\")\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "# Tes inferensi dengan ONNX Runtime\n",
    "ort_session = onnxruntime.InferenceSession(\"C:/Users/gravi/Documents/SistemLampu/Main/Sistem-lampu-lalu-lintas/yolov5/runs/train/exp24/weights/best.onnx\")\n",
    "\n",
    "# Cek apakah model berjalan tanpa error\n",
    "print(\"Model ONNX berhasil diuji!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m onnxruntime.quantization.preprocess --input runs/train/exp24/weights/best.onnx --output runs/train/exp24/weights/model_int8.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "quantize_dynamic(\"runs/train/exp24/weights/model_int8.onnx\", \"runs/train/exp24/weights/model_int8(quan).onnx\", weight_type=QuantType.QUInt8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "!python detect.py --weights runs/train/exp24/weights/best.pt --img 640 --conf 0.6 --source 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
